# âš½ Fine-Tuning e AvaliaÃ§Ã£o de LLMs para AnÃ¡lise de Futebol

Este repositÃ³rio contÃ©m um pipeline completo para treinamento, inferÃªncia e avaliaÃ§Ã£o de modelos de linguagem (LLMs) adaptados ao domÃ­nio futebolÃ­stico. O projeto utiliza dados reais extraÃ­dos da API do [Sofascore](https://www.sofascore.com), organizados para tarefas supervisionadas de classificaÃ§Ã£o e question answering (QA) no estilo Alpaca.

## ğŸ“‚ Estrutura do RepositÃ³rio

```
â”œâ”€â”€ get_players.ipynb      # Extrai estatÃ­sticas individuais de jogadores
â”œâ”€â”€ get_teams.ipynb        # Extrai estatÃ­sticas agregadas por time
â”œâ”€â”€ get_tables.ipynb       # Extrai e converte tabelas de classificaÃ§Ã£o por campeonato
â”œâ”€â”€ train_model.ipynb      # Realiza o fine-tuning supervisionado com Unsloth (LoRA 4-bit)
â”œâ”€â”€ evaluate_model.ipynb   # Avalia os modelos (fine-tuned, base e GPT-4o) com mÃ©tricas automÃ¡ticas
â”œâ”€â”€ /dados_rag_new         # Pasta com os arquivos CSV gerados (Google Drive ou local)
â””â”€â”€ README.md              # Este arquivo
```

## ğŸš€ VisÃ£o Geral das Etapas

### 1. `get_players.ipynb` â€“ Coleta de Dados de Jogadores

- Extrai estatÃ­sticas individuais por jogador em partidas encerradas.
- Filtra jogadores com base em posiÃ§Ã£o e estatÃ­sticas mÃ­nimas.
- Gera um dataset para classificaÃ§Ã£o de desempenho: **bom**, **mediano** ou **ruim**.
- Salva os dados como CSVs para cada campeonato e um consolidado para fine-tuning.

### 2. `get_teams.ipynb` â€“ Coleta de Dados de Times

- Coleta estatÃ­sticas de time por evento (posse, finalizaÃ§Ãµes, precisÃ£o de passes etc.).
- Classifica o desempenho de cada time por critÃ©rios heurÃ­sticos (xG, posse, chutes).
- Gera dataset supervisionado para classificaÃ§Ã£o do time por partida.

### 3. `get_tables.ipynb` â€“ ExtraÃ§Ã£o de Tabelas HierÃ¡rquicas

- Acessa diretamente endpoints da Sofascore para obter as classificaÃ§Ãµes por temporada.
- Gera exemplos de QA baseados em tabelas: 
  - Cell selection, Superlative, Aggregation, Difference, Average, Thresholds.
- Salva exemplos balanceados para uso no fine-tuning multitarefa.

### 4. `train_model.ipynb` â€“ Fine-Tuning Supervisionado

- Usa o framework [Unsloth](https://github.com/unslothai/unsloth) com LLaMA 3.1 8B quantizado (4bit).
- Aplica LoRA para ajuste eficiente com baixo uso de memÃ³ria.
- Treina com `SFTTrainer` por 60 steps (ajustÃ¡vel).
- Salva e publica os adaptadores LoRA no Hugging Face Hub.

### 5. `evaluate_model.ipynb` â€“ AvaliaÃ§Ã£o Comparativa de Modelos

- Compara 3 modelos: `Fine-Tuned`, `Base` (LLaMA 3.1) e `GPT-4o`.
- MÃ©tricas usadas:
  - **BLEU**, **ROUGE**, **BERTScore**, **METEOR**, **GPT-4 Score**
- Gera grÃ¡fico comparativo de desempenho entre os modelos.
- Exibe outputs lado a lado para anÃ¡lise qualitativa.

## ğŸ› ï¸ Requisitos

- Python 3.10+
- GPU com suporte a CUDA (mÃ­nimo: 12 GB VRAM para fine-tuning)
- Pacotes principais:
  - `unsloth`, `transformers`, `peft`, `trl`, `datasets`, `huggingface_hub`
  - `sacrebleu`, `rouge-score`, `bert-score`, `nltk`, `playwright`, `cloudscraper`

## ğŸ’¾ Dados

Os datasets gerados estÃ£o estruturados em CSVs:

- `processed_player_data_multi_championship.csv`
- `team_performance_<campeonato>.csv`
- `hierarchical_qa_dataset_balanced_all_seasons.csv`
- `player_performance_analysis_dataset.csv`

VocÃª pode adaptar o script para salvar os dados localmente ou em um diretÃ³rio montado do Google Drive.

## ğŸ“Š Exemplo de MÃ©tricas Comparativas

| Modelo       | BLEU | ROUGE-L | BERT-F1 | METEOR | GPT-4 Score |
|--------------|------|----------|---------|--------|--------------|
| Fine-Tuned   | 71.3 | 77.4     | 84.2    | 68.1   | 88.5         |
| Base         | 59.2 | 64.8     | 75.6    | 58.7   | 71.2         |
| GPT-4o       | 84.1 | 82.3     | 89.3    | 72.9   | 93.4         |

## ğŸ“¤ PublicaÃ§Ã£o no Hugging Face Hub

O modelo fine-tuned Ã© publicado em:

ğŸ‘‰ [`guilhermemoraisr/llama3-1-8B-4bit-lora-football-low-steps`](https://huggingface.co/guilhermemoraisr/llama3-1-8B-4bit-lora-football-low-steps)

## ğŸ“š ReferÃªncias

- [Unsloth: LLaMA Fine-Tuning Framework](https://github.com/unslothai/unsloth)
- [Sofascore Public API](https://www.sofascore.com)
- [Alpaca Format - Stanford CRFM](https://crfm.stanford.edu/2023/03/13/alpaca.html)
- [BERTScore](https://github.com/Tiiiger/bert_score)
- [GPT-4o API - OpenAI](https://platform.openai.com/docs/guides/gpt)